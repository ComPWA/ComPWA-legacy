{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart: $J/\\Psi \\rightarrow \\gamma \\pi^0 \\pi^0$ decay\n",
    "\n",
    "In this quickstart example it is shown how to use ComPWA via the python interface. The workflow is:\n",
    "\n",
    "1. Create a model for the decay.\n",
    "2. Generate a Monte Carlo data sample (hit & miss) using this model. \n",
    "3. Perform a fit on the data sample using the Minuit2 interface.\n",
    "4. Visualize the data and the fit result!\n",
    "\n",
    "Let's go!\n",
    "\n",
    "First we `import` the necessary expert system module parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycompwa.expertsystem.ui.system_control import (\n",
    "    StateTransitionManager, InteractionTypes)\n",
    "from pycompwa.expertsystem.amplitude.helicitydecay import (\n",
    "    HelicityDecayAmplitudeGeneratorXML)\n",
    "from pycompwa.expertsystem.topology.graph import (\n",
    "    get_intermediate_state_edges)\n",
    "\n",
    "# just a little function to print the intermediate states\n",
    "def print_intermediate_states(solutions):\n",
    "    print(\"intermediate states:\")\n",
    "    intermediate_states = set()\n",
    "    for g in solutions:\n",
    "        edge_id = get_intermediate_state_edges(g)[0]\n",
    "        intermediate_states.add(g.edge_props[edge_id]['@Name'])\n",
    "    print(intermediate_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Creating the Decay Model\n",
    "\n",
    "#### 1.1. Define problem set\n",
    "\n",
    "First we define the boundary conditions of our physics problem, such as\n",
    "\n",
    "- initial state\n",
    "- final state\n",
    "- formalism type\n",
    "- ...\n",
    "\n",
    "Pass all of that information to the `StateTransitionManager`, which is the main user interface class of the ComPWA expert system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = [(\"J/psi\", [-1, 1])]\n",
    "final_state = [(\"gamma\", [-1, 1]), (\"pi0\", [0]), (\"pi0\", [0])]\n",
    "\n",
    "tbd_manager = StateTransitionManager(initial_state, final_state,\n",
    "                                     formalism_type='helicity',\n",
    "                                     topology_building='isobar')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. note::\n",
    "   The ``StateTransitionManager`` (STM) is the main user interface class of the\n",
    "   ComPWA expert system. The boundary conditions of your physics problem are \n",
    "   defined here, such as the initial state, final state, formalism type, ...\n",
    "\n",
    "   * ``prepare_graphs()`` of the STM creates all topology graphs, here using\n",
    "     the isobar model (two-body decays). Also it initializes the graphs with\n",
    "     the initial and final state and the a set of conservation laws at each\n",
    "     interaction node.\n",
    "\n",
    "   * By default all three (strong, EM, weak) interaction types are used in the\n",
    "     preparation stage. However it is also possible to globally choose the\n",
    "     allowed interaction types via ``set_allowed_interaction_types()``.\n",
    "\n",
    "   After the preparation step, you can modifiy the settings returned by\n",
    "   ``prepare_graphs()`` to your liking. Since this output is quite a lot of\n",
    "   information, the expertsystem ui is supposed to aid in the configuration\n",
    "   (especially the STM).\n",
    "   \n",
    "   * A subset of particles that are allow as intermediate states can also be\n",
    "     specified in the STM. Either in the ``init()`` of the STM or setting the\n",
    "     instance attribute ``allowed_intermediate_particles``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Preparation\n",
    "Create all topology graphs using the isobar model (two-body decays).\n",
    "\n",
    "Also initialize the graphs with the initial and final state. Remember that each interaction node defines their own set of conservation laws. The `StateTransitionManager` (STM) defines three interaction types:\n",
    "\n",
    "| Interaction | Strength |\n",
    "| --- | --- |\n",
    "| strong | $60$ |\n",
    "| electromagnetic (EM) | $1$ |\n",
    "| weak | $10^{-4}$ |\n",
    "\n",
    "Be default all three are used in the preparation stage. `prepare_graphs()` of the STM generates graphs with all possible combinations of interaction nodes. An overall interaction strength is assigned to each graph, and they are grouped according to this strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_interaction_settings_groups = tbd_manager.prepare_graphs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Finding solutions\n",
    "If you are happy with the automatic settings generated by the StateTransitionManager, just go directly to the solving!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(solutions, violated_rules) = tbd_manager.find_solutions(\n",
    "        graph_interaction_settings_groups)\n",
    "\n",
    "print(\"found \" + str(len(solutions)) + \" solutions!\")\n",
    "print_intermediate_states(solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we have a lot of solutions that are actually heavily supressed (involve two weak decays). In general you can modify the dictionary return by `prepare_graphs()` directly.\n",
    "\n",
    "The STM also comes with a functionality to globally choose the allowed interaction types (`set_allowed_interaction_types()`). Go ahead and **disable** the **EM** and **weak** interaction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbd_manager.set_allowed_interaction_types(\n",
    "    [InteractionTypes.Strong])\n",
    "graph_interaction_settings_groups = tbd_manager.prepare_graphs()\n",
    "(solutions, violated_rules) = tbd_manager.find_solutions(\n",
    "        graph_interaction_settings_groups)\n",
    "print(\"found \" + str(len(solutions)) + \" solutions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh, what happened here? Actually, since a **gamma particle** appears, the expert system knows that there must be **at least one EM interaction** involved. As a consequence no graphs are prepared for this setting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph_interaction_settings_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's include the EM interaction..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbd_manager.set_allowed_interaction_types(\n",
    "    [InteractionTypes.Strong, InteractionTypes.EM])\n",
    "graph_interaction_settings_groups = tbd_manager.prepare_graphs()\n",
    "(solutions, violated_rules) = tbd_manager.find_solutions(\n",
    "        graph_interaction_settings_groups)\n",
    "\n",
    "print(\"found \" + str(len(solutions)) + \" solutions!\")\n",
    "print_intermediate_states(solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we selected the solutions that are contribution the strongest. However, be aware that there are more effects that can suppress certain decays. For example branching ratios. In this example $J/\\Psi$ can decay into $\\pi^0 + \\rho^0$ or $\\pi^0 + \\omega$.\n",
    "\n",
    "| decay | branching ratio |\n",
    "| --- | --- |\n",
    "| $$\\omega \\rightarrow \\gamma+\\pi^0$$ | 0.0828 |\n",
    "| $$\\rho^0 \\rightarrow \\gamma+\\pi^0$$ | 0.0006 |\n",
    "\n",
    "Unfortunately the $\\rho^0$ decays mainly into $\\pi+\\pi$, not $\\gamma+\\pi^0$. Hence it is suppressed. This information is currently not known to the expert system.\n",
    "But you can also tell the expert system, which particles you want to allow as intermediate states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# particles are found by name comparison; so i.e. f2 will find all f2's and f all f's\n",
    "tbd_manager.allowed_intermediate_particles = ['f']\n",
    "#tbd_manager.allowed_intermediate_particles = ['f2, f0']\n",
    "\n",
    "(solutions, violated_rules) = tbd_manager.find_solutions(\n",
    "        graph_interaction_settings_groups)\n",
    "\n",
    "print(\"found \" + str(len(solutions)) + \" solutions!\")\n",
    "print_intermediate_states(solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have selected all amplitudes that involve **f** states. At this point we are all set to generate some data using this amplitude model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_generator = HelicityDecayAmplitudeGeneratorXML()\n",
    "xml_generator.generate(solutions)\n",
    "xml_generator.write_to_file('model.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Creating a data sample\n",
    "\n",
    "In this section we will use the amplitude model created above to generate a data sample via hit & miss Monte Carlo.\n",
    "\n",
    "Using this amplitude model in the c++ side of ComPWA is simple. The `create_intensity_and_kinematics()` helper function builds an Intensity and Kinematics object, as specified in the xml file. These can be used to generate our data sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pycompwa is the python interface to ComPWA's c++ modules\n",
    "import pycompwa as pwa\n",
    "\n",
    "# create the intensity and kinematics\n",
    "intensity, kinematics = pwa.create_intensity_and_kinematics('model.xml')\n",
    "\n",
    "# use the RootGenerator to generate N particle events, as specified in the kinematics info\n",
    "generator = pwa.RootGenerator(kinematics.get_particle_state_transition_kinematics_info(), 12345)\n",
    "\n",
    "# generate data sample\n",
    "datasample = pwa.generate(5000, kinematics, generator, intensity)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. note::\n",
    "   ``pycompwa`` is the python interface to ComPWA's c++ modules. Read more\n",
    "   about this :ref:`here <python-ui>`.\n",
    "\n",
    "   Three important pieces for evaluating an intensity are:\n",
    "\n",
    "   * The **intensity** itself. It was generated previously and stored within\n",
    "     the xml model file.\n",
    "\n",
    "   * A **kinematics** instance. It handles the calculation of the kinematic\n",
    "     variables that are required for the evaluation of the intensity!\n",
    "     For example in the helicity formalism: :math:`(s,\\theta,\\phi)`.\n",
    "   \n",
    "   * **Data samples**. For mere visualization of the intensity a phase space\n",
    "     sample is sufficient. It is mandatory for the normalization of the\n",
    "     intensity. However when performing fits an additional data sample, to\n",
    "     which the intensity will be compared to, has to be specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Fitting\n",
    "\n",
    "All parameter defined and used by the **Intensity** object, can be obtain for it by using the `parameters()` function. Just pass it an empty `ParameterList` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_list = pwa.ParameterList()\n",
    "intensity.add_unique_parameters_to(par_list)\n",
    "fit_parameters = par_list.get_fit_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the true parameters in a dictionary so we can compare the fitted values later on. Notice that the `get_fit_parameters()` returns a special object that behave similar to a python list. The contents of the list are FitParameter objects, that have attributes `name, value, error, is_fixed`. The name and error attributes are read only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "true_parameters = {x.name: x.value for x in fit_parameters if not x.is_fixed}\n",
    "print(\"number of free fit parameters:\", len(true_parameters))\n",
    "print(true_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the fit a bit more interesting, we modify one of the parameters to a different initial value then the true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = fit_parameters.index(\"Magnitude_J/psi_to_f2(1270)_0+gamma_-1;f2(1270)_to_pi0_0;\")\n",
    "print(\"before:\", fit_parameters[idx])\n",
    "fit_parameters[idx].value = 2.0\n",
    "print(\"after:\",fit_parameters[idx])\n",
    "# we can also fix or free parameters here\n",
    "fit_parameters[fit_parameters.index(\n",
    "    'Phase_J/psi_to_f2(1270)_0+gamma_-1;f2(1270)_to_pi0_0;')].is_fixed = True\n",
    "print(\"should be fixed now.... \\n\",fit_parameters[fit_parameters.index(\n",
    "    'Phase_J/psi_to_f2(1270)_0+gamma_-1;f2(1270)_to_pi0_0;')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use an unbinned minimum log likelihood estimator to find the set of fit parameters of the intensity, that describe our data best. However in this example the intensity is not normalized. The minimum log likelihood estimator can handle the normalization for us, but a phase space data sample has to be supplied.\n",
    "\n",
    "**Note**: The intensities are evaluated with data points or parameterlists and not events, so they have to be converted using the kinematics class first. This way the data calculation is automatically cached!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phspsample = pwa.generate_phsp(100000, generator)\n",
    "datasample.convert_events_to_parameterlist(kinematics)\n",
    "phspsample.convert_events_to_parameterlist(kinematics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to start up a set up a fit, which is quite simple.\n",
    "1. First create an estimator instance of your choice, here a unbinned minimum log likelihood (`MinLogLH`). Notice that we use the function tree feature. This creates a full evaluation tree of the intensity, converting the data into a vertical layout (for cache optimization) and caching intermediate values of the intensity. It can greatly enhance the fit performance (here: 7 sec -> 150ms)! We use the `create_unbinned_log_likelihood_function_tree_estimator()` helper function to create the function tree version of our log LH estimator.\n",
    "2. Then create an optimizer instance of your choice, here Minuit2 (`MinuitIF`).\n",
    "\n",
    "**Note**: The runtime of the fit (with 15 free parameters) can take a couple of minutes (~5 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the next line creates a normal log likelihood estimator (without the function tree feature)\n",
    "#esti = pwa.MinLogLH(intensity, datasample, phspsample)\n",
    "\n",
    "estimator = pwa.create_unbinned_log_likelihood_function_tree_estimator(intensity, datasample, phspsample)\n",
    "minuitif = pwa.MinuitIF(estimator, par_list)\n",
    "minuitif.enable_hesse(True)\n",
    "\n",
    "result = minuitif.minimize(par_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the fit parameters are \"close to\" the true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fitresult_parameters = {x.name: (x.value, x.error) for x in fit_parameters if not x.is_fixed}\n",
    "for key, value in fitresult_parameters.items():\n",
    "    print(key, \" fit result:\", \"{0:.3f}\".format(value[0]), \"+-\", \n",
    "          \"({0:.3f},\".format(value[1][0]), \"{0:.3f})\".format(value[1][1]),\n",
    "          \" true:\", \"{0:.3f}\".format(true_parameters[key])\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Visualization\n",
    "Let's go ahead and make a Dalitz plot of the data sample and our fit result. ComPWA ships with a little plotting module to help you generate some common plots using matplotlib. Before we can utilize this, the data has to be extended.\n",
    "\n",
    "Since our model only includes one specific decay topology the `HelicityKinematics` class only generates the kinematic variables needed to evaluate the Intensity. In order to make a Dalitz plot, also the kinematic variables from the other subsystems are needed. They can be created with `create_all_subsystems()`. However the conversion from the event samples have to be performed again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinematics.create_all_subsystems()\n",
    "datasample.convert_events_to_datapoints(kinematics)\n",
    "phspsample.convert_events_to_datapoints(kinematics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is optional: create a ROOT file containing all of the information inside a TTree and read it back in again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwa.create_rootplotdata(\"rootplot.root\", kinematics, data_sample=datasample, \n",
    "                        phsp_sample=phspsample, intensity=intensity)\n",
    "\n",
    "from Plotting.ROOT.rootplotdatareader import open_compwa_plot_data\n",
    "\n",
    "plot_data = open_compwa_plot_data(\"rootplot.root\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ComPWA python interface has two helper functions `create_data_array()` `create_fitresult_array()` that allow the datapoins to be exported as two-dimensional lists. These can be used to create a numpy record arrays. Then the **Plotting** module is able to create common plots like the Dalitz plot."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. tip::\n",
    "   \n",
    "   ComPWA ships with a little python plotting module (``Plotting``), which for example helps you to read in ROOT TTree's and create common plots (e.g. angular distributions, Dalitz plots). It uses matplotlib as a backend. You can either hand it data files, or feed it directly with data.\n",
    "\n",
    "   Please use it, instead of creating your own visualization scripts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "from Plotting.plot import (\n",
    "    make_dalitz_plots, PlotData, create_nprecord,\n",
    "    make_difference_plot_2d\n",
    ")\n",
    "\n",
    "# use the direct data point access\n",
    "var_names, dataarray = pwa.create_data_array(datasample)\n",
    "data_record = create_nprecord(var_names, dataarray)\n",
    "\n",
    "fitres_var_names, fitres_dataarray = pwa.create_fitresult_array(intensity, phspsample)\n",
    "fitresult_record = create_nprecord(fitres_var_names, fitres_dataarray)\n",
    "\n",
    "plot_data = PlotData(data_record=data_record, fit_result_data_record=fitresult_record)\n",
    "#plot_data.particle_id_to_name_mapping = data_points.get_finalstate_id_to_name_mapping()\n",
    "# plot a 2d histogram\n",
    "make_dalitz_plots(plot_data, [\"mSq_3_4_vs_2\", \"mSq_2_4_vs_3\"], bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the differences more clearly visible we can create a 2d difference plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_difference_plot_2d(plot_data, [\"mSq_3_4_vs_2\", \"mSq_2_4_vs_3\"], bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it. You can check some of the other examples to learn about more detailed features of ComPWA.\n",
    "\n",
    "And give us feedback or contribute ;)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
